{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is adapted for running on a local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. General data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing packages\n",
    "\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sorting fMRI files ---\n",
    "\n",
    "# Creating a common dictionary of all fMRI files by study participant\n",
    "all_files = sorted(glob.glob(\n",
    "    \"Data/ds000113/sub-*/ses-movie/func/sub-*_ses-movie_task-movie_run-*_bold.nii.gz\"\n",
    "))\n",
    "\n",
    "def extract_subject_id(path):\n",
    "    match = re.search(r\"sub-(\\d+)\", path)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "subject_runs = defaultdict(list)\n",
    "\n",
    "for path in all_files:\n",
    "    subject_id = extract_subject_id(path)\n",
    "    if subject_id:\n",
    "        subject_runs[subject_id].append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cleaning up the emotion annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Creating a common dataframe with all the emotions --- \n",
    "allemotion = glob.glob('Data/gump_emotions/raw/av1o0*.csv')\n",
    "emotiondf = []\n",
    "for file in allemotion:\n",
    "    df = pd.read_csv(file)\n",
    "    df['participant'] = file \n",
    "    emotiondf.append(df)\n",
    "\n",
    "# Removing the non-labeled moments\n",
    "emotiondf = [df.dropna(subset=['emotion']) for df in emotiondf]\n",
    "emotions = pd.concat(emotiondf, ignore_index=True) \n",
    "\n",
    "# Adding the TR correspondents to every label\n",
    "TR = 2  # TR in seconds chosen based on the fMRI configuration\n",
    "\n",
    "emotions['start_tr'] = np.floor(emotions['start']  / TR).astype(int)\n",
    "emotions['end_tr']   = np.ceil (emotions['end']    / TR).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Creating a new dataframe of the format: ----\n",
    "#\n",
    "#           Participant 1 | Participant 2 | ... | Participant 7 | General Emotion\n",
    "# TR1       Emotion_x        NaN                    Emotion_x     Emotion_x\n",
    "# TR2\n",
    "# .\n",
    "# .\n",
    "# TR_final\n",
    "#\n",
    "\n",
    "\n",
    "max_tr = emotions['end_tr'].max()   \n",
    "n_TRs  = max_tr                    \n",
    "participants = emotions['participant'].unique()\n",
    "\n",
    "wide = pd.DataFrame(\n",
    "    index = range(n_TRs),\n",
    "    columns = participants,\n",
    "    data = np.nan\n",
    ")\n",
    "\n",
    "for _, row in emotions.iterrows():\n",
    "    pid       = row['participant']      # Participant ID\n",
    "    start_tr  = int(row['start_tr'])    # When the label starts\n",
    "    end_tr    = int(row['end_tr'])      # When the label ends\n",
    "    label     = row['emotion']          # The label itself\n",
    "\n",
    "    wide.loc[start_tr:end_tr-1, pid] = label\n",
    "\n",
    "wide['general_emotion'] = wide.mode(axis=1)[0]\n",
    "\n",
    "# Renaming the columns and indices\n",
    "wide.index.name      = 'global_TR'\n",
    "wide.columns.name    = 'participant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 1010 of 3526 TRs where ≥5 participants (half of 9) agreed\n"
     ]
    }
   ],
   "source": [
    "# --- Keeping only the labels agreed upon by half of the participants ---\n",
    "\n",
    "participant_cols = [c for c in wide.columns if c != 'general_emotion']\n",
    "n_participants = len(participant_cols)\n",
    "half_thresh = math.ceil(n_participants / 2)\n",
    "\n",
    "def half_of_all_consensus(row):\n",
    "    counts = row[participant_cols].value_counts(dropna=True)\n",
    "    if counts.empty:\n",
    "        return False\n",
    "    top_count = counts.iloc[0]\n",
    "    return top_count >= half_thresh\n",
    "\n",
    "mask = wide.apply(half_of_all_consensus, axis=1)\n",
    "\n",
    "wide_consensus_all = wide.loc[mask].copy()\n",
    "print(f\"Kept {len(wide_consensus_all)} of {len(wide)} TRs where ≥{half_thresh} participants (half of {n_participants}) agreed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Determining the individual fMRI segments in terms of TRs as reported in the underlying paper (Labs et al. ) ---\n",
    "\n",
    "TR = 2.0\n",
    "segments = [\n",
    "    (   0.0,  902.0),\n",
    "    ( 886.0, 1768.0),\n",
    "    (1752.0, 2628.0),\n",
    "    (2612.0, 3588.0),\n",
    "    (3572.0, 4496.0),\n",
    "    (4480.0, 5358.0),\n",
    "    (5342.0, 6426.0),\n",
    "    (6410.0, 7086.0),\n",
    "]\n",
    "\n",
    "# Finding the starting TRs and length in TRs\n",
    "run_lengths = [int((e - s) / TR) for s, e in segments]\n",
    "run_starts  = np.cumsum([0] + run_lengths[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "general_emotion\n",
      "FEAR              236\n",
      "SADNESS           235\n",
      "HAPPINESS         206\n",
      "ANGERRAGE         143\n",
      "LOVE               78\n",
      "DISAPPOINTMENT     25\n",
      "ADMIRATION         18\n",
      "CONTEMPT           12\n",
      "PRIDE              11\n",
      "COMPASSION         10\n",
      "SHAME              10\n",
      "REMORSE             9\n",
      "GLOATING            6\n",
      "GRATITUDE           4\n",
      "RELIEF              3\n",
      "HOPE                2\n",
      "HATE                2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#--- Inspecting amount of labels ---\n",
    "label_counts = wide_consensus_all['general_emotion'].value_counts()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/03t5vzrs7zgbycw7q8mm4svw0000gn/T/ipykernel_94218/2455505344.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda grp: grp.sample(n=threshold, random_state=0))\n"
     ]
    }
   ],
   "source": [
    "#--- Balancing the labels ---\n",
    "\n",
    "# Value to keep for each emotion\n",
    "threshold = 70      \n",
    "\n",
    "df = wide_consensus_all[['general_emotion']].reset_index() \n",
    "counts = df['general_emotion'].value_counts()\n",
    "keep = counts[counts >= threshold].index\n",
    "df = df[df['general_emotion'].isin(keep)]\n",
    "\n",
    "\n",
    "balanced = (\n",
    "    df\n",
    "    .groupby('general_emotion', group_keys=False)\n",
    "    .apply(lambda grp: grp.sample(n=threshold, random_state=0))\n",
    ")\n",
    "\n",
    "sampled_TRs = balanced['global_TR'].values\n",
    "wide_balanced = wide_consensus_all.loc[sampled_TRs].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data prep for the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5250 examples from cache.\n"
     ]
    }
   ],
   "source": [
    "#--- Creating a metadata dictionary for the fMRI data ---\n",
    "\n",
    "CACHE_PATH = 'Xmetadata.pkl'\n",
    "if os.path.exists(CACHE_PATH):\n",
    "    with open(CACHE_PATH, 'rb') as f:\n",
    "        examples = pickle.load(f)\n",
    "    print(f\"Loaded {len(examples)} examples from cache.\")\n",
    "else:\n",
    "\n",
    "    def tr_to_run_idx(tr):\n",
    "        for ri, start in enumerate(run_starts):\n",
    "            if start <= tr < start + run_lengths[ri]:\n",
    "                return ri, int(tr - start)\n",
    "        raise ValueError(f\"TR {tr} out of bounds\")\n",
    "\n",
    "    examples = []\n",
    "    for subj, run_files in tqdm(subject_runs.items()):\n",
    "        for global_tr in wide_balanced.index:\n",
    "            run_idx, local_tr = tr_to_run_idx(global_tr)\n",
    "            filepath = run_files[run_idx]\n",
    "            img      = nib.load(filepath)\n",
    "            vol3d    = img.dataobj[..., local_tr]\n",
    "            examples.append({\n",
    "                'subject': subj,\n",
    "                'run_idx': run_idx+1,\n",
    "                'TR_local': local_tr,\n",
    "                'label':   wide_balanced.at[global_tr,'general_emotion'],\n",
    "                'volume':  vol3d,\n",
    "                'affine':  img.affine\n",
    "            })\n",
    "\n",
    "    with open(CACHE_PATH, 'wb') as f:\n",
    "        pickle.dump(examples, f)\n",
    "        print(f\"Computed and cached {len(examples)} examples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1050 validation indices to val_indices.pkl.\n"
     ]
    }
   ],
   "source": [
    "#--- Creating a training/testing split ---\n",
    "labels = [ex['label'] for ex in examples]\n",
    "indices = list(range(len(examples)))\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    indices,\n",
    "    test_size=0.2,\n",
    "    stratify=labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Saving the indices of validation dataset for later usage\n",
    "with open('valindices.pkl', 'wb') as f:\n",
    "    pickle.dump(val_idx, f)\n",
    "    print(f\"Saved {len(val_idx)} validation indices to val_indices.pkl.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Necessary preparations for the model ---\n",
    "\n",
    "# Creating a mapping between labels and their integer indices\n",
    "unique_labels = sorted({ex['label'] for ex in examples})\n",
    "label_to_int  = {lab: i for i, lab in enumerate(unique_labels)}\n",
    "\n",
    "# Processing the metadata into lists \n",
    "vol_list, label_list, meta_list = [], [], []\n",
    "for ex in examples:\n",
    "    vol = ex['volume']  # shape = (X, Y, Z), numpy\n",
    "\n",
    "    # Normalizing the data\n",
    "    mu, sigma = vol.mean(), vol.std()\n",
    "    vol = (vol - mu) / (sigma + 1e-6)\n",
    "\n",
    "    # Filling the lists and reshaping the training data for the model\n",
    "    vol_list.append(vol[np.newaxis, ...])            # now (1, X, Y, Z)\n",
    "    label_list.append(label_to_int[ex['label']])\n",
    "    meta_list.append({\n",
    "        'subject':  ex['subject'],\n",
    "        'run_idx':  ex['run_idx'],\n",
    "        'TR_local': ex['TR_local'],\n",
    "        'affine':   ex['affine'],\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Exporting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Generating and exporting X_train, y_train, X_val, y_val ---\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.stack(vol_list)  # Shape: (N, 1, X, Y, Z)\n",
    "y = np.array(label_list)  # Shape: (N,)\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val = X[train_idx], X[val_idx]\n",
    "y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "# Define base path for saving\n",
    "base = 'readydata'\n",
    "os.makedirs(base, exist_ok=True)\n",
    "\n",
    "# Save the datasets\n",
    "torch.save(torch.from_numpy(X_train).float(), f'{base}/X_train.pt')\n",
    "torch.save(torch.from_numpy(y_train).long(), f'{base}/y_train.pt')\n",
    "torch.save(torch.from_numpy(X_val).float(), f'{base}/X_val.pt')\n",
    "torch.save(torch.from_numpy(y_val).long(), f'{base}/y_val.pt')\n",
    "\n",
    "print(f\"Exported datasets to '{base}' directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
